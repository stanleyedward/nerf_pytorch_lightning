{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import get_ray_directions, get_rays\n",
    "import os\n",
    "import json\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "import lightning as L\n",
    "from rendering import rendering\n",
    "from utils import test\n",
    "\n",
    "from dataset import LegoDataset, LegoDataModule\n",
    "from model import Nerf\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lego_dataset = LegoDataset(root_dir=\"dataset/lego/\", split=\"test\", img_shape=(400, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# hyperparams\n",
    "tn = 2.0\n",
    "tf = 6.0\n",
    "nb_epochs = 16\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.5\n",
    "nb_bins = 100\n",
    "\n",
    "model = Nerf().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[2, 4, 8], gamma=gamma\n",
    ")\n",
    "\n",
    "\n",
    "# warmup on 1 epoch\n",
    "training_loss = training(\n",
    "    model, optimizer, scheduler, warmup_dataloader, tn, tf, nb_bins, 1, device\n",
    ")\n",
    "plt.plot(training_loss)\n",
    "plt.show()\n",
    "\n",
    "# training_loss = training(model, optimizer, scheduler, train_dataloader, tn, tf, nb_bins, nb_epochs, device)\n",
    "# plt.plot(training_loss)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# nerf_model = torch.load(\"models/model_nerf\").to(device)\n",
    "# nerf_model.eval()\n",
    "\n",
    "# hyperparams\n",
    "tn = 2.0\n",
    "tf = 6.0\n",
    "nb_epochs = 16\n",
    "learning_rate = 5e-4\n",
    "gamma = 0.5\n",
    "nb_bins = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from model import NeRFLightning\n",
    "\n",
    "lit_nerf = NeRFLightning.load_from_checkpoint(\"models/16_epoch_192_bins_400_nerf.ckpt\")\n",
    "lit_nerf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import test\n",
    "\n",
    "for idx in range(0, 200):\n",
    "    img, mse, psnr = test(\n",
    "        lit_nerf,\n",
    "        lego_dataset[idx][\"rays_origin\"].reshape(-1, 3).to(device).type(torch.float),\n",
    "        lego_dataset[idx][\"rays_direction\"].reshape(-1, 3).to(device).type(torch.float),\n",
    "        tn,\n",
    "        tf,\n",
    "        image_index=idx,\n",
    "        nb_bins=192,\n",
    "        chunk_size=10,\n",
    "        height=lego_dataset.img_shape[0],\n",
    "        width=lego_dataset.img_shape[1],\n",
    "        target=lego_dataset[idx][\"rgbs\"].numpy(),\n",
    "        outputs_dir=\"lkjasdaf\",\n",
    "        metrics=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lit ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lit_nerf.state_dict()\n",
    "# torch.save(obj=lit_nerf.state_dict(), f=\"models/lit_nerf_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### litmodel as nn.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import Nerf\n",
    "\n",
    "checkpoint = torch.load(\"models/epoch=16-step=83670.ckpt\")\n",
    "# since keys dont align properly here\n",
    "mapped_state_dict = {}\n",
    "for k, v in checkpoint[\"state_dict\"].items():\n",
    "    if k.startswith(\"nerf.\"):  # If checkpoint keys start with \"nerf.\", remove it\n",
    "        mapped_state_dict[k[len(\"nerf.\") :]] = v\n",
    "    else:\n",
    "        mapped_state_dict[k] = v\n",
    "nerf = Nerf().to(device)\n",
    "nerf.load_state_dict(mapped_state_dict)\n",
    "torch.save(obj=nerf.state_dict(), f=\"models/16_epoch_192_bins_400_nerf.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "img, mse, psnr = test(\n",
    "    lit_nerf,\n",
    "    lego_dataset[idx][\"rays_origin\"].reshape(-1, 3).to(device).type(torch.float),\n",
    "    lego_dataset[idx][\"rays_direction\"].reshape(-1, 3).to(device).type(torch.float),\n",
    "    tn,\n",
    "    tf,\n",
    "    image_index=idx,\n",
    "    nb_bins=100,\n",
    "    chunk_size=20,\n",
    "    height=lego_dataset.img_shape[0],\n",
    "    width=lego_dataset.img_shape[1],\n",
    "    target=lego_dataset[idx][\"rgbs\"].numpy(),\n",
    "    outputs_dir=\"tbuadslfjk\",\n",
    "    metrics=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29.200356294523996, 0.0012457877128773586)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_avg_metrics(outputs_json_dir: str) -> Tuple[float, float]:\n",
    "    with open(\"outputs/nerf_testing.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    avg_psnr = sum(data[\"psnr\"]) / len(data[\"psnr\"])\n",
    "    avg_mse = sum(data[\"mse\"]) / len(data[\"mse\"])\n",
    "    return avg_psnr, avg_mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
